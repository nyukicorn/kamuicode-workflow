#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„éŸ³æ¥½åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ - ç¾ã—ã„ãƒãƒ©ã®èŠ±æŸ
éŸ³éŸ¿ç‰¹æ€§ã€æ¥½å™¨åˆ†æã€æ§‹é€ åˆ†æã€æˆ¦ç•¥æ¯”è¼ƒã‚’å®Ÿè¡Œ
"""

import numpy as np
import librosa
import librosa.display
import soundfile as sf
from scipy import signal
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import os
import json
from datetime import datetime

class ComprehensiveMusicAnalyzer:
    def __init__(self, audio_file_path):
        self.audio_file_path = audio_file_path
        self.y, self.sr = librosa.load(audio_file_path)
        self.duration = len(self.y) / self.sr
        self.analysis_results = {}
        
    def analyze_basic_characteristics(self):
        """åŸºæœ¬éŸ³éŸ¿ç‰¹æ€§ã®åˆ†æ"""
        print("=== åŸºæœ¬éŸ³éŸ¿ç‰¹æ€§åˆ†æ ===")
        
        # æ›²ã®é•·ã•
        duration_seconds = self.duration
        print(f"æ¥½æ›²ã®é•·ã•: {duration_seconds:.2f}ç§’")
        
        # ãƒ†ãƒ³ãƒæ¸¬å®š
        tempo, beats = librosa.beat.beat_track(y=self.y, sr=self.sr)
        print(f"æ¨å®šãƒ†ãƒ³ãƒ: {tempo:.1f} BPM")
        
        # ã‚­ãƒ¼/èª¿æ€§ã®åˆ¤å®š
        chroma = librosa.feature.chroma_stft(y=self.y, sr=self.sr)
        key_profile = np.mean(chroma, axis=1)
        key_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
        estimated_key = key_names[np.argmax(key_profile)]
        print(f"æ¨å®šã‚­ãƒ¼: {estimated_key}")
        
        # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã¨å‹•çš„ãƒ¬ãƒ³ã‚¸
        rms = librosa.feature.rms(y=self.y)[0]
        avg_rms = np.mean(rms)
        max_rms = np.max(rms)
        min_rms = np.min(rms)
        dynamic_range = 20 * np.log10(max_rms / (min_rms + 1e-10))
        
        print(f"å¹³å‡RMS: {avg_rms:.4f}")
        print(f"æœ€å¤§RMS: {max_rms:.4f}")
        print(f"æœ€å°RMS: {min_rms:.4f}")
        print(f"å‹•çš„ãƒ¬ãƒ³ã‚¸: {dynamic_range:.1f} dB")
        
        self.analysis_results['basic'] = {
            'duration': duration_seconds,
            'tempo': float(tempo),
            'estimated_key': estimated_key,
            'average_rms': float(avg_rms),
            'max_rms': float(max_rms),
            'min_rms': float(min_rms),
            'dynamic_range': float(dynamic_range)
        }
        
    def analyze_instruments_and_timbre(self):
        """æ¥½å™¨ãƒ»éŸ³è‰²åˆ†æ"""
        print("\n=== æ¥½å™¨ãƒ»éŸ³è‰²åˆ†æ ===")
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ è§£æ
        stft = librosa.stft(self.y)
        magnitude = np.abs(stft)
        
        # å‘¨æ³¢æ•°å¸¯åŸŸåˆ¥ã‚¨ãƒãƒ«ã‚®ãƒ¼åˆ†æ
        freqs = librosa.fft_frequencies(sr=self.sr)
        
        # ä½åŸŸ (20-250Hz) - ä½éŸ³æ¥½å™¨
        low_freq_mask = (freqs >= 20) & (freqs <= 250)
        low_energy = np.mean(magnitude[low_freq_mask])
        
        # ä¸­åŸŸ (250-4000Hz) - ãƒ¡ãƒ­ãƒ‡ã‚£æ¥½å™¨
        mid_freq_mask = (freqs >= 250) & (freqs <= 4000)
        mid_energy = np.mean(magnitude[mid_freq_mask])
        
        # é«˜åŸŸ (4000-20000Hz) - é«˜éŸ³æ¥½å™¨ã€å€éŸ³
        high_freq_mask = (freqs >= 4000) & (freqs <= 20000)
        high_energy = np.mean(magnitude[high_freq_mask])
        
        print(f"ä½åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ (20-250Hz): {low_energy:.4f}")
        print(f"ä¸­åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ (250-4000Hz): {mid_energy:.4f}")
        print(f"é«˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ (4000-20000Hz): {high_energy:.4f}")
        
        # æ¥½å™¨æ¨å®š
        total_energy = low_energy + mid_energy + high_energy
        low_ratio = low_energy / total_energy
        mid_ratio = mid_energy / total_energy
        high_ratio = high_energy / total_energy
        
        print(f"ä½åŸŸæ¯”ç‡: {low_ratio:.1%}")
        print(f"ä¸­åŸŸæ¯”ç‡: {mid_ratio:.1%}")
        print(f"é«˜åŸŸæ¯”ç‡: {high_ratio:.1%}")
        
        # æ¥½å™¨ç‰¹å®šãƒ­ã‚¸ãƒƒã‚¯
        instruments = []
        if mid_ratio > 0.5:
            instruments.append("ãƒ”ã‚¢ãƒ (ä¸­åŸŸå„ªå‹¢)")
        if low_ratio > 0.2:
            instruments.append("ã‚¹ãƒˆãƒªãƒ³ã‚°ã‚¹/ãƒã‚§ãƒ­ (ä½åŸŸæ”¯æŒ)")
        if high_ratio > 0.3:
            instruments.append("ãƒ•ãƒ«ãƒ¼ãƒˆ/é«˜éŸ³æ¥½å™¨ (é«˜åŸŸã‚¢ã‚¯ã‚»ãƒ³ãƒˆ)")
            
        print(f"æ¨å®šæ¥½å™¨: {', '.join(instruments)}")
        
        # ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ç‰¹å¾´
        spectral_centroid = librosa.feature.spectral_centroid(y=self.y, sr=self.sr)[0]
        spectral_rolloff = librosa.feature.spectral_rolloff(y=self.y, sr=self.sr)[0]
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=self.y, sr=self.sr)[0]
        
        avg_centroid = np.mean(spectral_centroid)
        avg_rolloff = np.mean(spectral_rolloff)
        avg_bandwidth = np.mean(spectral_bandwidth)
        
        print(f"ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«é‡å¿ƒ: {avg_centroid:.1f} Hz")
        print(f"ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ãƒ­ãƒ¼ãƒ«ã‚ªãƒ•: {avg_rolloff:.1f} Hz")
        print(f"ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«å¸¯åŸŸå¹…: {avg_bandwidth:.1f} Hz")
        
        # éŸ³è‰²ç‰¹å¾´åˆ¤å®š
        timbre_characteristics = []
        if avg_centroid < 2000:
            timbre_characteristics.append("æš–ã‹ã„éŸ³è‰²")
        else:
            timbre_characteristics.append("æ˜ã‚‹ã„éŸ³è‰²")
            
        if avg_bandwidth < 1500:
            timbre_characteristics.append("æŸ”ã‚‰ã‹ã„è³ªæ„Ÿ")
        else:
            timbre_characteristics.append("é®®æ˜ãªè³ªæ„Ÿ")
            
        print(f"éŸ³è‰²ç‰¹å¾´: {', '.join(timbre_characteristics)}")
        
        self.analysis_results['instruments'] = {
            'frequency_distribution': {
                'low_energy': float(low_energy),
                'mid_energy': float(mid_energy),
                'high_energy': float(high_energy),
                'low_ratio': float(low_ratio),
                'mid_ratio': float(mid_ratio),
                'high_ratio': float(high_ratio)
            },
            'estimated_instruments': instruments,
            'spectral_features': {
                'centroid': float(avg_centroid),
                'rolloff': float(avg_rolloff),
                'bandwidth': float(avg_bandwidth)
            },
            'timbre_characteristics': timbre_characteristics
        }
        
    def analyze_structure(self):
        """æ§‹é€ åˆ†æ"""
        print("\n=== æ§‹é€ åˆ†æ ===")
        
        # RMSã‚¨ãƒãƒ«ã‚®ãƒ¼ã®æ™‚é–“å¤‰åŒ–
        rms = librosa.feature.rms(y=self.y, frame_length=2048, hop_length=512)[0]
        times = librosa.frames_to_time(np.arange(len(rms)), sr=self.sr, hop_length=512)
        
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼å¤‰åŒ–ã®åˆ†æ
        rms_smooth = signal.savgol_filter(rms, window_length=21, polyorder=3)
        
        # ãƒ”ãƒ¼ã‚¯æ¤œå‡º
        peaks, _ = signal.find_peaks(rms_smooth, height=np.mean(rms_smooth))
        peak_times = times[peaks]
        
        print(f"ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ”ãƒ¼ã‚¯æ•°: {len(peaks)}")
        print(f"ãƒ”ãƒ¼ã‚¯æ™‚åˆ»: {peak_times}")
        
        # æ¥½æ›²ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¨å®š
        duration = self.duration
        sections = []
        
        if duration > 30:
            # æ¨™æº–çš„ãªæ§‹é€  (>30ç§’)
            intro_end = min(8, duration * 0.2)
            development_end = min(20, duration * 0.6)
            climax_end = min(30, duration * 0.8)
            
            sections = [
                {'name': 'ã‚¤ãƒ³ãƒˆãƒ­', 'start': 0, 'end': intro_end},
                {'name': 'å±•é–‹éƒ¨', 'start': intro_end, 'end': development_end},
                {'name': 'ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹', 'start': development_end, 'end': climax_end},
                {'name': 'ã‚¢ã‚¦ãƒˆãƒ­', 'start': climax_end, 'end': duration}
            ]
        else:
            # çŸ­ã„æ§‹é€  (<30ç§’)
            intro_end = duration * 0.25
            development_end = duration * 0.7
            
            sections = [
                {'name': 'ã‚¤ãƒ³ãƒˆãƒ­', 'start': 0, 'end': intro_end},
                {'name': 'å±•é–‹éƒ¨', 'start': intro_end, 'end': development_end},
                {'name': 'ã‚¢ã‚¦ãƒˆãƒ­', 'start': development_end, 'end': duration}
            ]
        
        print("\næ¥½æ›²æ§‹é€ :")
        for section in sections:
            duration_sec = section['end'] - section['start']
            print(f"  {section['name']}: {section['start']:.1f}-{section['end']:.1f}ç§’ ({duration_sec:.1f}ç§’)")
        
        # æ„Ÿæƒ…æ›²ç·šã®åˆ†æ
        emotion_curve = rms_smooth / np.max(rms_smooth)  # æ­£è¦åŒ–
        
        # æ„Ÿæƒ…çš„é«˜æšãƒã‚¤ãƒ³ãƒˆ
        high_emotion_threshold = np.percentile(emotion_curve, 80)
        high_emotion_indices = np.where(emotion_curve > high_emotion_threshold)[0]
        high_emotion_times = times[high_emotion_indices]
        
        print(f"\næ„Ÿæƒ…çš„é«˜æšãƒã‚¤ãƒ³ãƒˆ (ä¸Šä½20%): {len(high_emotion_indices)}ãƒã‚¤ãƒ³ãƒˆ")
        if len(high_emotion_times) > 0:
            print(f"ä¸»è¦é«˜æšæ™‚åˆ»: {high_emotion_times[0]:.1f}ç§’ - {high_emotion_times[-1]:.1f}ç§’")
        
        self.analysis_results['structure'] = {
            'total_duration': float(duration),
            'energy_peaks': len(peaks),
            'peak_times': [float(t) for t in peak_times],
            'sections': sections,
            'emotion_curve_stats': {
                'max_emotion_time': float(times[np.argmax(emotion_curve)]),
                'min_emotion_time': float(times[np.argmin(emotion_curve)]),
                'high_emotion_duration': float(len(high_emotion_indices) * 512 / self.sr)
            }
        }
        
    def compare_with_strategy(self):
        """æˆ¦ç•¥è¨ˆç”»ã¨ã®æ¯”è¼ƒ"""
        print("\n=== æˆ¦ç•¥è¨ˆç”»ã¨ã®æ¯”è¼ƒåˆ†æ ===")
        
        # è¨ˆç”»ã•ã‚ŒãŸä»•æ§˜
        planned_specs = {
            'tempo_range': (60, 70),
            'duration_range': (30, 40),
            'key': 'C Major',
            'instruments': ['ãƒ”ã‚¢ãƒ', 'ã‚¹ãƒˆãƒªãƒ³ã‚°ã‚¹', 'ãƒ•ãƒ«ãƒ¼ãƒˆ'],
            'structure': ['é™å¯‚', 'å„ªé›…ãªé–‹èŠ±', 'ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹', 'ä½™éŸ»']
        }
        
        actual_specs = self.analysis_results
        
        print("=== ãƒ†ãƒ³ãƒæ¯”è¼ƒ ===")
        actual_tempo = actual_specs['basic']['tempo']
        planned_min, planned_max = planned_specs['tempo_range']
        tempo_match = planned_min <= actual_tempo <= planned_max
        print(f"è¨ˆç”»ãƒ†ãƒ³ãƒ: {planned_min}-{planned_max} BPM")
        print(f"å®Ÿéš›ãƒ†ãƒ³ãƒ: {actual_tempo:.1f} BPM")
        print(f"ãƒ†ãƒ³ãƒä¸€è‡´: {'âœ“' if tempo_match else 'âœ—'}")
        
        print("\n=== æ¥½æ›²é•·æ¯”è¼ƒ ===")
        actual_duration = actual_specs['basic']['duration']
        planned_min_dur, planned_max_dur = planned_specs['duration_range']
        duration_match = planned_min_dur <= actual_duration <= planned_max_dur
        print(f"è¨ˆç”»é•·ã•: {planned_min_dur}-{planned_max_dur}ç§’")
        print(f"å®Ÿéš›é•·ã•: {actual_duration:.1f}ç§’")
        print(f"é•·ã•ä¸€è‡´: {'âœ“' if duration_match else 'âœ—'}")
        
        print("\n=== ã‚­ãƒ¼æ¯”è¼ƒ ===")
        actual_key = actual_specs['basic']['estimated_key']
        planned_key = planned_specs['key'].split()[0]  # 'C Major' -> 'C'
        key_match = actual_key == planned_key
        print(f"è¨ˆç”»ã‚­ãƒ¼: {planned_specs['key']}")
        print(f"æ¨å®šã‚­ãƒ¼: {actual_key}")
        print(f"ã‚­ãƒ¼ä¸€è‡´: {'âœ“' if key_match else 'âœ—'}")
        
        print("\n=== æ¥½å™¨æ§‹æˆæ¯”è¼ƒ ===")
        planned_instruments = planned_specs['instruments']
        actual_instruments = actual_specs['instruments']['estimated_instruments']
        print(f"è¨ˆç”»æ¥½å™¨: {', '.join(planned_instruments)}")
        print(f"æ¨å®šæ¥½å™¨: {', '.join(actual_instruments)}")
        
        # æ¥½å™¨ãƒãƒƒãƒãƒ³ã‚°åˆ†æ
        instrument_matches = []
        for planned in planned_instruments:
            for actual in actual_instruments:
                if planned in actual or any(word in actual for word in planned.split()):
                    instrument_matches.append(planned)
                    break
        
        instrument_match_rate = len(instrument_matches) / len(planned_instruments)
        print(f"æ¥½å™¨ä¸€è‡´ç‡: {instrument_match_rate:.1%}")
        
        print("\n=== æ§‹é€ æ¯”è¼ƒ ===")
        planned_structure = planned_specs['structure']
        actual_sections = [s['name'] for s in actual_specs['structure']['sections']]
        print(f"è¨ˆç”»æ§‹é€ : {' â†’ '.join(planned_structure)}")
        print(f"å®Ÿéš›æ§‹é€ : {' â†’ '.join(actual_sections)}")
        
        # ç·åˆä¸€è‡´ç‡
        matches = [tempo_match, duration_match, key_match, instrument_match_rate > 0.5]
        overall_match_rate = sum(matches) / len(matches)
        
        print(f"\n=== ç·åˆè©•ä¾¡ ===")
        print(f"æˆ¦ç•¥å®Ÿç¾åº¦: {overall_match_rate:.1%}")
        
        self.analysis_results['strategy_comparison'] = {
            'tempo_match': tempo_match,
            'duration_match': duration_match,
            'key_match': key_match,
            'instrument_match_rate': float(instrument_match_rate),
            'overall_match_rate': float(overall_match_rate),
            'recommendations': []
        }
        
    def generate_prompt_recommendations(self):
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¾®èª¿æ•´ã®ãŸã‚ã®æ¨å¥¨äº‹é …"""
        print("\n=== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¾®èª¿æ•´æ¨å¥¨äº‹é … ===")
        
        recommendations = []
        actual = self.analysis_results
        
        # ãƒ†ãƒ³ãƒã«åŸºã¥ãæ¨å¥¨
        actual_tempo = actual['basic']['tempo']
        if actual_tempo < 60:
            recommendations.append({
                'category': 'ãƒ†ãƒ³ãƒèª¿æ•´',
                'issue': f'å®Ÿéš›ã®ãƒ†ãƒ³ãƒ({actual_tempo:.1f} BPM)ãŒè¨ˆç”»ã‚ˆã‚Šé…ã„',
                'recommendation': 'ç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚ˆã‚Šé™çš„ã§ç‘æƒ³çš„ãªè¡¨ç¾ã‚’å¼·èª¿',
                'video_prompt_adjustment': 'ã‚†ã£ãã‚Šã¨ã—ãŸèŠ±ã³ã‚‰ã®å‹•ãã€é™å¯‚ãªç¾ã—ã•ã‚’é‡è¦–'
            })
        elif actual_tempo > 70:
            recommendations.append({
                'category': 'ãƒ†ãƒ³ãƒèª¿æ•´',
                'issue': f'å®Ÿéš›ã®ãƒ†ãƒ³ãƒ({actual_tempo:.1f} BPM)ãŒè¨ˆç”»ã‚ˆã‚Šé€Ÿã„',
                'recommendation': 'ç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚ˆã‚Šå‹•çš„ã§æ´»æ°—ã®ã‚ã‚‹è¡¨ç¾ã‚’è¿½åŠ ',
                'video_prompt_adjustment': 'èŠ±ã³ã‚‰ã®èºå‹•æ„Ÿã€å…‰ã®å‹•çš„å¤‰åŒ–ã‚’å¼·èª¿'
            })
        
        # æ¥½å™¨æ§‹æˆã«åŸºã¥ãæ¨å¥¨
        mid_ratio = actual['instruments']['frequency_distribution']['mid_ratio']
        high_ratio = actual['instruments']['frequency_distribution']['high_ratio']
        
        if mid_ratio > 0.6:
            recommendations.append({
                'category': 'æ¥½å™¨ãƒãƒ©ãƒ³ã‚¹',
                'issue': 'ãƒ”ã‚¢ãƒï¼ˆä¸­åŸŸï¼‰ãŒæ”¯é…çš„',
                'recommendation': 'ç”»åƒã§ãƒ”ã‚¢ãƒã®å„ªé›…ã•ã‚’å¼·èª¿ã€ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚„éŸ³ç¬¦ã®ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«è¦ç´ ',
                'video_prompt_adjustment': 'ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆãªæŒ‡ã®å‹•ãã€éµç›¤ã®åå°„ã‚’æƒ³èµ·ã•ã›ã‚‹å…‰ã®è¡¨ç¾'
            })
        
        if high_ratio > 0.3:
            recommendations.append({
                'category': 'ãƒ•ãƒ«ãƒ¼ãƒˆã‚¢ã‚¯ã‚»ãƒ³ãƒˆ',
                'issue': 'é«˜åŸŸæ¥½å™¨ï¼ˆãƒ•ãƒ«ãƒ¼ãƒˆï¼‰ãŒæ˜ç¢ºã«å­˜åœ¨',
                'recommendation': 'è»½ã‚„ã‹ã§é€æ˜æ„Ÿã®ã‚ã‚‹è¦–è¦šè¦ç´ ã‚’è¿½åŠ ',
                'video_prompt_adjustment': 'é¢¨ã«èˆã†èŠ±ã³ã‚‰ã€é€æ˜ãªå…‰ã®ç²’å­ã€ç©ºæ°—æ„Ÿã®ã‚ã‚‹å‹•ã'
            })
        
        # å‹•çš„ãƒ¬ãƒ³ã‚¸ã«åŸºã¥ãæ¨å¥¨
        dynamic_range = actual['basic']['dynamic_range']
        if dynamic_range < 10:
            recommendations.append({
                'category': 'å‹•çš„è¡¨ç¾',
                'issue': f'å‹•çš„ãƒ¬ãƒ³ã‚¸ãŒå°ã•ã„({dynamic_range:.1f} dB)',
                'recommendation': 'ä¸€å®šã®ç¾ã—ã•ã‚’ä¿ã¤é™çš„ãªç¾ã—ã•ã‚’é‡è¦–',
                'video_prompt_adjustment': 'å®‰å®šã—ãŸç…§æ˜ã€ç©ã‚„ã‹ãªè‰²å½©å¤‰åŒ–'
            })
        elif dynamic_range > 20:
            recommendations.append({
                'category': 'å‹•çš„è¡¨ç¾',
                'issue': f'å‹•çš„ãƒ¬ãƒ³ã‚¸ãŒå¤§ãã„({dynamic_range:.1f} dB)',
                'recommendation': 'åŠ‡çš„ãªæ˜æš—ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã€ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªè¦–è¦šå¤‰åŒ–',
                'video_prompt_adjustment': 'åŠ‡çš„ãªç…§æ˜å¤‰åŒ–ã€å½±ã¨å…‰ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ'
            })
        
        # æ§‹é€ ã«åŸºã¥ãæ¨å¥¨
        sections = actual['structure']['sections']
        if len(sections) == 3:  # çŸ­ã„æ§‹é€ 
            recommendations.append({
                'category': 'æ§‹é€ é©å¿œ',
                'issue': 'æ¥½æ›²ãŒçŸ­ã„æ§‹é€ ï¼ˆ3ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰',
                'recommendation': 'å„å‹•ç”»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ã‚ˆã‚Šé›†ä¸­çš„ã«ä½¿ç”¨',
                'video_prompt_adjustment': 'å„5ç§’å‹•ç”»ã®è¦ç´ ã‚’æœ€å¤§é™æ´»ç”¨ã€é‡è¤‡ä½¿ç”¨ã®åŠ¹æœçš„æ´»ç”¨'
            })
        
        # æˆ¦ç•¥è¨ˆç”»ã®å½¹å‰²åˆ†æ‹…èª¿æ•´
        role_adjustments = {
            'ãƒ¡ã‚¤ãƒ³å‹•ç”»(60%)': 'ãƒ”ã‚¢ãƒä¸­å¿ƒã®å„ªé›…ãªè¡¨ç¾ã«ç„¦ç‚¹ã€å®‰å®šã—ãŸç¾ã—ã•',
            'ã‚¢ã‚¯ã‚»ãƒ³ãƒˆå‹•ç”»(25%)': 'é«˜åŸŸæ¥½å™¨ã«åˆã‚ã›ãŸè»½ã‚„ã‹ã§é€æ˜ãªè¡¨ç¾',
            'ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³å‹•ç”»(15%)': 'å‹•çš„ãƒ¬ãƒ³ã‚¸ã«åˆã‚ã›ãŸç¹‹ãã®å¼·å¼±èª¿æ•´'
        }
        
        print("\n=== å½¹å‰²åˆ†æ‹…èª¿æ•´æ¨å¥¨ ===")
        for role, adjustment in role_adjustments.items():
            print(f"{role}: {adjustment}")
            recommendations.append({
                'category': 'å½¹å‰²åˆ†æ‹…',
                'issue': role,
                'recommendation': adjustment,
                'video_prompt_adjustment': adjustment
            })
        
        print(f"\nç·æ¨å¥¨äº‹é …æ•°: {len(recommendations)}")
        for i, rec in enumerate(recommendations, 1):
            print(f"{i}. [{rec['category']}] {rec['recommendation']}")
        
        self.analysis_results['recommendations'] = recommendations
        
    def save_analysis_results(self, output_dir):
        """åˆ†æçµæœã®ä¿å­˜"""
        os.makedirs(output_dir, exist_ok=True)
        
        # JSONå½¢å¼ã§ä¿å­˜
        json_path = os.path.join(output_dir, 'music_analysis_results.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2)
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        report_path = os.path.join(output_dir, 'detailed-music-analysis-report.md')
        self._generate_markdown_report(report_path)
        
        print(f"\n=== åˆ†æçµæœä¿å­˜å®Œäº† ===")
        print(f"JSON: {json_path}")
        print(f"ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
        
    def _generate_markdown_report(self, report_path):
        """è©³ç´°ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        basic = self.analysis_results['basic']
        instruments = self.analysis_results['instruments']
        structure = self.analysis_results['structure']
        comparison = self.analysis_results['strategy_comparison']
        recommendations = self.analysis_results['recommendations']
        
        report = f"""# éŸ³æ¥½è©³ç´°åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - ç¾ã—ã„ãƒãƒ©ã®èŠ±æŸ

## åˆ†ææ¦‚è¦
- **åˆ†ææ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
- **éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«**: {os.path.basename(self.audio_file_path)}
- **ç·åˆæˆ¦ç•¥å®Ÿç¾åº¦**: {comparison['overall_match_rate']:.1%}

## 1. åŸºæœ¬éŸ³éŸ¿ç‰¹æ€§

### æ¥½æ›²åŸºæœ¬æƒ…å ±
- **æ¥½æ›²ã®é•·ã•**: {basic['duration']:.2f}ç§’
- **æ¨å®šãƒ†ãƒ³ãƒ**: {basic['tempo']:.1f} BPM
- **æ¨å®šã‚­ãƒ¼**: {basic['estimated_key']}

### éŸ³éŸ¿ãƒ¬ãƒ™ãƒ«åˆ†æ
- **å¹³å‡RMSãƒ¬ãƒ™ãƒ«**: {basic['average_rms']:.4f}
- **æœ€å¤§RMSãƒ¬ãƒ™ãƒ«**: {basic['max_rms']:.4f}
- **æœ€å°RMSãƒ¬ãƒ™ãƒ«**: {basic['min_rms']:.4f}
- **å‹•çš„ãƒ¬ãƒ³ã‚¸**: {basic['dynamic_range']:.1f} dB

## 2. æ¥½å™¨ãƒ»éŸ³è‰²åˆ†æ

### å‘¨æ³¢æ•°å¸¯åŸŸåˆ¥åˆ†æ
- **ä½åŸŸ (20-250Hz)**: {instruments['frequency_distribution']['low_energy']:.4f} ({instruments['frequency_distribution']['low_ratio']:.1%})
- **ä¸­åŸŸ (250-4000Hz)**: {instruments['frequency_distribution']['mid_energy']:.4f} ({instruments['frequency_distribution']['mid_ratio']:.1%})
- **é«˜åŸŸ (4000-20000Hz)**: {instruments['frequency_distribution']['high_energy']:.4f} ({instruments['frequency_distribution']['high_ratio']:.1%})

### æ¨å®šæ¥½å™¨
{chr(10).join(f'- {instrument}' for instrument in instruments['estimated_instruments'])}

### ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ç‰¹å¾´
- **ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«é‡å¿ƒ**: {instruments['spectral_features']['centroid']:.1f} Hz
- **ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«ãƒ­ãƒ¼ãƒ«ã‚ªãƒ•**: {instruments['spectral_features']['rolloff']:.1f} Hz
- **ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ«å¸¯åŸŸå¹…**: {instruments['spectral_features']['bandwidth']:.1f} Hz

### éŸ³è‰²ç‰¹å¾´
{chr(10).join(f'- {char}' for char in instruments['timbre_characteristics'])}

## 3. æ§‹é€ åˆ†æ

### æ¥½æ›²æ§‹é€ 
{chr(10).join(f'- **{section["name"]}**: {section["start"]:.1f}-{section["end"]:.1f}ç§’ ({section["end"]-section["start"]:.1f}ç§’)' for section in structure['sections'])}

### æ„Ÿæƒ…æ›²ç·šåˆ†æ
- **æœ€å¤§æ„Ÿæƒ…ãƒã‚¤ãƒ³ãƒˆ**: {structure['emotion_curve_stats']['max_emotion_time']:.1f}ç§’
- **æœ€å°æ„Ÿæƒ…ãƒã‚¤ãƒ³ãƒˆ**: {structure['emotion_curve_stats']['min_emotion_time']:.1f}ç§’
- **é«˜æšç¶™ç¶šæ™‚é–“**: {structure['emotion_curve_stats']['high_emotion_duration']:.1f}ç§’
- **ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ”ãƒ¼ã‚¯æ•°**: {structure['energy_peaks']}

## 4. æˆ¦ç•¥è¨ˆç”»ã¨ã®æ¯”è¼ƒ

### ä»•æ§˜ä¸€è‡´åº¦
- **ãƒ†ãƒ³ãƒä¸€è‡´**: {'âœ“ åˆè‡´' if comparison['tempo_match'] else 'âœ— ä¸ä¸€è‡´'}
- **æ¥½æ›²é•·ä¸€è‡´**: {'âœ“ åˆè‡´' if comparison['duration_match'] else 'âœ— ä¸ä¸€è‡´'}
- **ã‚­ãƒ¼ä¸€è‡´**: {'âœ“ åˆè‡´' if comparison['key_match'] else 'âœ— ä¸ä¸€è‡´'}
- **æ¥½å™¨æ§‹æˆä¸€è‡´ç‡**: {comparison['instrument_match_rate']:.1%}

### ç·åˆè©•ä¾¡
**æˆ¦ç•¥å®Ÿç¾åº¦: {comparison['overall_match_rate']:.1%}**

## 5. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¾®èª¿æ•´æ¨å¥¨äº‹é …

### ç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´ææ¡ˆ
"""
        
        for i, rec in enumerate(recommendations, 1):
            report += f"""
#### {i}. {rec['category']}
- **å•é¡Œ**: {rec['issue']}
- **æ¨å¥¨**: {rec['recommendation']}
- **å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆèª¿æ•´**: {rec['video_prompt_adjustment']}
"""
        
        report += f"""

## 6. å½¹å‰²åˆ†æ‹…ç¶­æŒã®ãŸã‚ã®å¾®èª¿æ•´æ¡ˆ

### ãƒ¡ã‚¤ãƒ³å‹•ç”» (60% ä½¿ç”¨ç‡) 
- ç¾åœ¨ã®éŸ³æ¥½ç‰¹æ€§ã«åŸºã¥ãã€{instruments['frequency_distribution']['mid_ratio']:.1%}ã®ä¸­åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ´»ã‹ã—ãŸå„ªé›…ãªãƒ”ã‚¢ãƒè¡¨ç¾ã«ç„¦ç‚¹
- å®‰å®šã—ãŸç¾ã—ã•ã‚’è¡¨ç¾ã™ã‚‹é™çš„è¦ç´ ã‚’é‡è¦–

### ã‚¢ã‚¯ã‚»ãƒ³ãƒˆå‹•ç”» (25% ä½¿ç”¨ç‡)
- {instruments['frequency_distribution']['high_ratio']:.1%}ã®é«˜åŸŸã‚¨ãƒãƒ«ã‚®ãƒ¼ã‚’æ´»ã‹ã—ãŸè»½ã‚„ã‹ãªè¡¨ç¾
- é€æ˜æ„Ÿã¨èºå‹•æ„Ÿã®ãƒãƒ©ãƒ³ã‚¹

### ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³å‹•ç”» (15% ä½¿ç”¨ç‡)  
- {basic['dynamic_range']:.1f}dBã®å‹•çš„ãƒ¬ãƒ³ã‚¸ã«åˆã‚ã›ãŸç¹‹ãã®å¼·å¼±
- æ„Ÿæƒ…ã®æ©‹æ¸¡ã—åŠ¹æœã®æœ€é©åŒ–

## 7. æŠ€è¡“çš„è€ƒæ…®äº‹é …

- **å®Ÿéš›BPM ({basic['tempo']:.1f})** ã«åŸºã¥ãå‹•ç”»é€Ÿåº¦èª¿æ•´æ¨å¥¨
- **å‹•çš„ãƒ¬ãƒ³ã‚¸ ({basic['dynamic_range']:.1f}dB)** ã«åˆã‚ã›ãŸè¦–è¦šçš„ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´
- **æ¥½æ›²é•· ({basic['duration']:.1f}ç§’)** ã§ã®3å‹•ç”»æœ€é©é…åˆ†æˆ¦ç•¥

---
*ã“ã®åˆ†æã¯æ¥½æ›²ã®å®Ÿéš›ã®ç‰¹æ€§ã«åŸºã¥ãã€æˆ¦ç•¥è¨ˆç”»ã¨ã®æ•´åˆæ€§ã‚’ä¿ã¡ã¤ã¤æœ€é©åŒ–ã‚’å›³ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚*
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
    
    def run_full_analysis(self):
        """å®Œå…¨åˆ†æã®å®Ÿè¡Œ"""
        print("ğŸµ åŒ…æ‹¬çš„éŸ³æ¥½åˆ†æé–‹å§‹ ğŸµ\n")
        
        self.analyze_basic_characteristics()
        self.analyze_instruments_and_timbre()
        self.analyze_structure()
        self.compare_with_strategy()
        self.generate_prompt_recommendations()
        
        print("\nâœ… åˆ†æå®Œäº† âœ…")
        
        return self.analysis_results

def main():
    # éŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    audio_file = "/home/runner/work/kamuicode-workflow/kamuicode-workflow/music-video-20250722-16448947063/music/generated-music.wav"
    output_dir = "/home/runner/work/kamuicode-workflow/kamuicode-workflow/music-video-20250722-16448947063/analysis"
    
    # åˆ†æå®Ÿè¡Œ
    analyzer = ComprehensiveMusicAnalyzer(audio_file)
    results = analyzer.run_full_analysis()
    
    # çµæœä¿å­˜
    analyzer.save_analysis_results(output_dir)
    
    print(f"\nğŸ“Š è©³ç´°åˆ†æå®Œäº†!")
    print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {output_dir}")

if __name__ == "__main__":
    main()