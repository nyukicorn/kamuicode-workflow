#!/usr/bin/env python3
"""
åŸºæœ¬çš„ãªéŸ³æ¥½ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨waveãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨
"""

import wave
import os
import struct
import math

def basic_wav_analysis(filepath):
    """WAVãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬åˆ†æ"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not os.path.exists(filepath):
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}"}
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = os.path.getsize(filepath)
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with wave.open(filepath, 'rb') as wav_file:
            # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            frames = wav_file.getnframes()
            sample_rate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            
            # é•·ã•è¨ˆç®—
            duration = frames / sample_rate
            
            # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
            raw_audio = wav_file.readframes(frames)
            
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿è§£æ
        if sample_width == 2:  # 16-bit
            audio_data = struct.unpack(f'<{frames * channels}h', raw_audio)
        elif sample_width == 1:  # 8-bit
            audio_data = struct.unpack(f'<{frames * channels}B', raw_audio)
        else:
            audio_data = []
        
        # åŸºæœ¬çµ±è¨ˆ
        if audio_data:
            max_amplitude = max(abs(x) for x in audio_data)
            rms = math.sqrt(sum(x*x for x in audio_data) / len(audio_data))
            dynamic_range_approx = max_amplitude / (rms + 1) if rms > 0 else 0
        else:
            max_amplitude = 0
            rms = 0
            dynamic_range_approx = 0
        
        # æ§‹é€ æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        # éŸ³é‡ãƒ¬ãƒ™ãƒ«ã®å¤‰åŒ–ã‚’è¿½è·¡ã—ã¦æ§‹é€ ã‚’æ¨å®š
        segment_length = sample_rate * 2  # 2ç§’ã”ã¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        segments = []
        
        for i in range(0, len(audio_data), segment_length):
            segment = audio_data[i:i+segment_length]
            if segment:
                segment_rms = math.sqrt(sum(x*x for x in segment) / len(segment))
                segments.append(segment_rms)
        
        # ç°¡å˜ãªBPMæ¨å®šï¼ˆéå¸¸ã«ç²—ã„è¿‘ä¼¼ï¼‰
        # ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ”ãƒ¼ã‚¯ã®é–“éš”ã‚’æ¸¬å®š
        energy_peaks = []
        for i, rms in enumerate(segments):
            if i > 0 and i < len(segments) - 1:
                if rms > segments[i-1] and rms > segments[i+1]:
                    energy_peaks.append(i * 2)  # æ™‚é–“ï¼ˆç§’ï¼‰
        
        estimated_bpm = 0
        if len(energy_peaks) > 1:
            avg_interval = sum(energy_peaks[i+1] - energy_peaks[i] for i in range(len(energy_peaks)-1)) / (len(energy_peaks)-1)
            if avg_interval > 0:
                estimated_bpm = 60 / avg_interval
        
        return {
            "file_info": {
                "file_size_bytes": file_size,
                "file_size_mb": round(file_size / (1024*1024), 2),
                "duration_seconds": round(duration, 2),
                "sample_rate": sample_rate,
                "channels": channels,
                "sample_width_bytes": sample_width,
                "total_frames": frames
            },
            "audio_analysis": {
                "max_amplitude": max_amplitude,
                "rms_average": round(rms, 2),
                "dynamic_range_ratio": round(dynamic_range_approx, 2),
                "estimated_bpm": round(estimated_bpm, 1) if estimated_bpm > 0 else "æ¨å®šä¸å¯",
                "energy_segments": len(segments),
                "energy_peaks_count": len(energy_peaks)
            },
            "structure_estimate": {
                "total_segments": len(segments),
                "peak_positions_seconds": energy_peaks,
                "estimated_intro_length": min(8, duration * 0.2),
                "estimated_outro_length": min(8, duration * 0.2)
            }
        }
        
    except Exception as e:
        return {"error": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"}

def generate_comparison_report(analysis_result, target_specs):
    """åˆ†æçµæœã¨ç›®æ¨™ä»•æ§˜ã®æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ"""
    report = []
    
    if "error" in analysis_result:
        return [f"âŒ ã‚¨ãƒ©ãƒ¼: {analysis_result['error']}"]
    
    file_info = analysis_result["file_info"]
    audio_info = analysis_result["audio_analysis"]
    
    # é•·ã•ã®æ¯”è¼ƒ
    duration = file_info["duration_seconds"]
    target_duration = target_specs.get("duration", (30, 40))
    if isinstance(target_duration, tuple):
        if target_duration[0] <= duration <= target_duration[1]:
            report.append(f"âœ… é•·ã•: {duration}ç§’ (ç›®æ¨™ç¯„å›²: {target_duration[0]}-{target_duration[1]}ç§’)")
        else:
            report.append(f"âš ï¸ é•·ã•: {duration}ç§’ (ç›®æ¨™ç¯„å›²å¤–: {target_duration[0]}-{target_duration[1]}ç§’)")
    else:
        report.append(f"ğŸ“ é•·ã•: {duration}ç§’")
    
    # BPMã®æ¯”è¼ƒ
    estimated_bpm = audio_info["estimated_bpm"]
    target_bpm = target_specs.get("bpm", (80, 100))
    if isinstance(estimated_bpm, (int, float)) and isinstance(target_bpm, tuple):
        if target_bpm[0] <= estimated_bpm <= target_bpm[1]:
            report.append(f"âœ… BPM: {estimated_bpm} (ç›®æ¨™ç¯„å›²: {target_bpm[0]}-{target_bpm[1]})")
        else:
            report.append(f"âš ï¸ BPM: {estimated_bpm} (ç›®æ¨™ç¯„å›²å¤–: {target_bpm[0]}-{target_bpm[1]})")
    else:
        report.append(f"ğŸ¥ BPM: {estimated_bpm}")
    
    # å“è³ªæŒ‡æ¨™
    report.append(f"ğŸ”Š éŸ³è³ª: {file_info['sample_rate']}Hz, {file_info['sample_width_bytes']*8}bit, {'ã‚¹ãƒ†ãƒ¬ã‚ª' if file_info['channels']==2 else 'ãƒ¢ãƒãƒ©ãƒ«'}")
    report.append(f"ğŸ“Š ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹æ¯”: {audio_info['dynamic_range_ratio']}")
    report.append(f"ğŸµ æ¤œå‡ºãƒ”ãƒ¼ã‚¯æ•°: {audio_info['energy_peaks_count']}")
    
    return report

def main():
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    audio_file = "/home/runner/work/kamuicode-workflow/kamuicode-workflow/music-video-20250721-16406899626/music/generated-music.wav"
    
    print("ğŸµ åŸºæœ¬éŸ³æ¥½åˆ†æå®Ÿè¡Œä¸­...")
    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {audio_file}")
    print("-" * 60)
    
    # åˆ†æå®Ÿè¡Œ
    result = basic_wav_analysis(audio_file)
    
    # ç›®æ¨™ä»•æ§˜
    target_specs = {
        "duration": (30, 40),  # ç§’
        "bpm": (80, 100),      # BPMç¯„å›²
        "style": "ãƒŸãƒ‹ãƒãƒªã‚¹ãƒˆãƒ”ã‚¢ãƒã‚½ãƒ­"
    }
    
    # çµæœè¡¨ç¤º
    if "error" in result:
        print(f"âŒ {result['error']}")
        return
    
    # åŸºæœ¬æƒ…å ±
    file_info = result["file_info"]
    audio_info = result["audio_analysis"]
    structure = result["structure_estimate"]
    
    print("ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«åŸºæœ¬æƒ…å ±:")
    print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_info['file_size_mb']} MB")
    print(f"  é•·ã•: {file_info['duration_seconds']} ç§’")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {file_info['sample_rate']} Hz")
    print(f"  ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {file_info['channels']}")
    print(f"  ãƒ“ãƒƒãƒˆæ·±åº¦: {file_info['sample_width_bytes'] * 8} bit")
    
    print(f"\nğŸ” éŸ³æ¥½åˆ†æ:")
    print(f"  æœ€å¤§æŒ¯å¹…: {audio_info['max_amplitude']}")
    print(f"  RMSå¹³å‡: {audio_info['rms_average']}")
    print(f"  ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹æ¯”: {audio_info['dynamic_range_ratio']}")
    print(f"  æ¨å®šBPM: {audio_info['estimated_bpm']}")
    print(f"  ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ”ãƒ¼ã‚¯æ•°: {audio_info['energy_peaks_count']}")
    
    print(f"\nğŸ—ï¸ æ§‹é€ æ¨å®š:")
    print(f"  åˆ†æã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {structure['total_segments']}")
    print(f"  ãƒ”ãƒ¼ã‚¯ä½ç½®: {structure['peak_positions_seconds']}")
    print(f"  æ¨å®šã‚¤ãƒ³ãƒˆãƒ­é•·: {structure['estimated_intro_length']:.1f}ç§’")
    print(f"  æ¨å®šã‚¢ã‚¦ãƒˆãƒ­é•·: {structure['estimated_outro_length']:.1f}ç§’")
    
    print(f"\nğŸ“‹ ç›®æ¨™ä»•æ§˜ã¨ã®æ¯”è¼ƒ:")
    comparison = generate_comparison_report(result, target_specs)
    for item in comparison:
        print(f"  {item}")
    
    print(f"\nğŸ¨ è¦–è¦šçš„è¦ç´ ã¸ã®ç¤ºå”†:")
    
    # åŸºæœ¬çš„ãªè¦–è¦šææ¡ˆ
    duration = file_info['duration_seconds']
    estimated_bpm = audio_info.get('estimated_bpm', 90)
    
    if isinstance(estimated_bpm, (int, float)):
        if estimated_bpm < 80:
            visual_rhythm = "ã‚†ã£ãã‚Šã¨ã—ãŸç‘æƒ³çš„ãªå‹•ã"
        elif estimated_bpm < 100:
            visual_rhythm = "ç©ã‚„ã‹ã§æµã‚Œã‚‹ã‚ˆã†ãªå‹•ã"
        else:
            visual_rhythm = "ãƒªã‚ºãƒŸã‚«ãƒ«ãªå‹•ã"
    else:
        visual_rhythm = "å®‰å®šã—ãŸç©ã‚„ã‹ãªå‹•ã"
    
    print(f"  æ¨å¥¨è¦–è¦šãƒªã‚ºãƒ : {visual_rhythm}")
    
    if duration < 35:
        print(f"  æ§‹æˆææ¡ˆ: ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãª3æ®µæ§‹æˆï¼ˆã‚¤ãƒ³ãƒˆãƒ­â†’å±•é–‹â†’ã‚¢ã‚¦ãƒˆãƒ­ï¼‰")
    else:
        print(f"  æ§‹æˆææ¡ˆ: 4æ®µæ§‹æˆï¼ˆã‚¤ãƒ³ãƒˆãƒ­â†’å±•é–‹â†’ã‚¯ãƒ©ã‚¤ãƒãƒƒã‚¯ã‚¹â†’ã‚¢ã‚¦ãƒˆãƒ­ï¼‰")
    
    dynamic_ratio = audio_info.get('dynamic_range_ratio', 1)
    if dynamic_ratio > 3:
        print(f"  ç…§æ˜ææ¡ˆ: ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªæ˜æš—å¤‰åŒ–")
    else:
        print(f"  ç…§æ˜ææ¡ˆ: æŸ”ã‚‰ã‹ãå®‰å®šã—ãŸç…§æ˜")
    
    print(f"  è‰²å½©ææ¡ˆ: ãƒŸãƒ‹ãƒãƒ«ã§æ¸…æ½”æ„Ÿã®ã‚ã‚‹è‰²èª¿")
    
    print("-" * 60)
    print("âœ… åŸºæœ¬åˆ†æå®Œäº†")

if __name__ == "__main__":
    main()