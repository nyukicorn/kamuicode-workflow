#!/usr/bin/env python3
"""
åŸºæœ¬éŸ³æ¥½åˆ†æå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å®Ÿéš›ã®æ¸¬å®šãƒ‡ãƒ¼ã‚¿å–å¾—
"""

import wave
import os
import struct
import math
import json
from datetime import datetime

def basic_wav_analysis(filepath):
    """WAVãƒ•ã‚¡ã‚¤ãƒ«ã®åŸºæœ¬åˆ†æ"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not os.path.exists(filepath):
            return {"error": f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}"}
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
        file_size = os.path.getsize(filepath)
        
        # WAVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        with wave.open(filepath, 'rb') as wav_file:
            # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            frames = wav_file.getnframes()
            sample_rate = wav_file.getframerate()
            channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            
            # é•·ã•è¨ˆç®—
            duration = frames / sample_rate
            
            # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ èª­ã¿è¾¼ã¿
            raw_audio = wav_file.readframes(frames)
            
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿è§£æ
        if sample_width == 2:  # 16-bit
            audio_data = struct.unpack(f'<{frames * channels}h', raw_audio)
        elif sample_width == 1:  # 8-bit
            audio_data = struct.unpack(f'<{frames * channels}B', raw_audio)
        else:
            audio_data = []
        
        # åŸºæœ¬çµ±è¨ˆ
        if audio_data:
            max_amplitude = max(abs(x) for x in audio_data)
            rms = math.sqrt(sum(x*x for x in audio_data) / len(audio_data))
            dynamic_range_approx = max_amplitude / (rms + 1) if rms > 0 else 0
        else:
            max_amplitude = 0
            rms = 0
            dynamic_range_approx = 0
        
        # æ§‹é€ æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰
        segment_length = sample_rate * 2  # 2ç§’ã”ã¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        segments = []
        
        for i in range(0, len(audio_data), segment_length):
            segment = audio_data[i:i+segment_length]
            if segment:
                segment_rms = math.sqrt(sum(x*x for x in segment) / len(segment))
                segments.append(segment_rms)
        
        # ç°¡å˜ãªBPMæ¨å®š
        energy_peaks = []
        for i, rms in enumerate(segments):
            if i > 0 and i < len(segments) - 1:
                if rms > segments[i-1] and rms > segments[i+1]:
                    energy_peaks.append(i * 2)  # æ™‚é–“ï¼ˆç§’ï¼‰
        
        estimated_bpm = 0
        if len(energy_peaks) > 1:
            avg_interval = sum(energy_peaks[i+1] - energy_peaks[i] for i in range(len(energy_peaks)-1)) / (len(energy_peaks)-1)
            if avg_interval > 0:
                estimated_bpm = 60 / avg_interval
        
        return {
            "file_info": {
                "file_size_bytes": file_size,
                "file_size_mb": round(file_size / (1024*1024), 2),
                "duration_seconds": round(duration, 2),
                "sample_rate": sample_rate,
                "channels": channels,
                "sample_width_bytes": sample_width,
                "total_frames": frames
            },
            "audio_analysis": {
                "max_amplitude": max_amplitude,
                "rms_average": round(rms, 2),
                "dynamic_range_ratio": round(dynamic_range_approx, 2),
                "estimated_bpm": round(estimated_bpm, 1) if estimated_bpm > 0 else "æ¨å®šä¸å¯",
                "energy_segments": len(segments),
                "energy_peaks_count": len(energy_peaks),
                "energy_peaks_times": energy_peaks
            },
            "structure_estimate": {
                "total_segments": len(segments),
                "peak_positions_seconds": energy_peaks,
                "estimated_intro_length": min(8, duration * 0.2),
                "estimated_outro_length": min(8, duration * 0.2),
                "segment_rms_values": segments
            }
        }
        
    except Exception as e:
        return {"error": f"åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"}

def generate_plan_comparison(result, target_specs):
    """è¨ˆç”»ã¨ã®è©³ç´°æ¯”è¼ƒ"""
    if "error" in result:
        return {"error": result["error"]}
    
    file_info = result["file_info"]
    audio_info = result["audio_analysis"]
    
    comparison = {}
    
    # é•·ã•æ¯”è¼ƒ
    duration = file_info["duration_seconds"]
    target_duration = target_specs["duration"]
    if target_duration[0] <= duration <= target_duration[1]:
        comparison["duration"] = {
            "status": "âœ… é©åˆ",
            "actual": f"{duration}ç§’",
            "target": f"{target_duration[0]}-{target_duration[1]}ç§’",
            "deviation": "ç¯„å›²å†…"
        }
    else:
        deviation = min(abs(duration - target_duration[0]), abs(duration - target_duration[1]))
        comparison["duration"] = {
            "status": "âš ï¸ ç¯„å›²å¤–",
            "actual": f"{duration}ç§’",
            "target": f"{target_duration[0]}-{target_duration[1]}ç§’",
            "deviation": f"{deviation:.1f}ç§’å·®"
        }
    
    # BPMæ¯”è¼ƒ
    estimated_bpm = audio_info["estimated_bpm"]
    target_bpm = target_specs["bpm"]
    if isinstance(estimated_bpm, (int, float)):
        if target_bpm[0] <= estimated_bpm <= target_bpm[1]:
            comparison["bpm"] = {
                "status": "âœ… é©åˆ",
                "actual": f"{estimated_bpm} BPM",
                "target": f"{target_bpm[0]}-{target_bpm[1]} BPM",
                "deviation": "ç¯„å›²å†…"
            }
        else:
            deviation = min(abs(estimated_bpm - target_bpm[0]), abs(estimated_bpm - target_bpm[1]))
            comparison["bpm"] = {
                "status": "âš ï¸ ç¯„å›²å¤–",
                "actual": f"{estimated_bpm} BPM",
                "target": f"{target_bpm[0]}-{target_bpm[1]} BPM",
                "deviation": f"{deviation:.1f} BPMå·®"
            }
    else:
        comparison["bpm"] = {
            "status": "â“ æ¨å®šä¸å¯",
            "actual": str(estimated_bpm),
            "target": f"{target_bpm[0]}-{target_bpm[1]} BPM",
            "deviation": "æ¸¬å®šå›°é›£"
        }
    
    return comparison

def analyze_structure_sections(result, target_structure):
    """æ§‹é€ åˆ†æã®è©³ç´°"""
    if "error" in result:
        return {"error": result["error"]}
    
    duration = result["file_info"]["duration_seconds"]
    peaks = result["structure_estimate"]["peak_positions_seconds"]
    
    # ç†æƒ³çš„ãªæ§‹é€ ã¨ã®æ¯”è¼ƒ
    ideal_intro_end = target_structure["intro"]
    ideal_development_end = ideal_intro_end + target_structure["development"][1]
    ideal_climax_end = ideal_development_end + target_structure["climax"][1]
    
    analysis = {
        "actual_structure": {
            "total_duration": duration,
            "peak_count": len(peaks),
            "peak_times": peaks
        },
        "target_structure": target_structure,
        "section_analysis": {}
    }
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ¨å®š
    if duration > 0:
        intro_ratio = min(8, duration * 0.2) / duration
        outro_ratio = min(8, duration * 0.2) / duration
        development_ratio = 1 - intro_ratio - outro_ratio
        
        analysis["section_analysis"] = {
            "estimated_intro": f"0-{min(8, duration * 0.2):.1f}ç§’",
            "estimated_development": f"{min(8, duration * 0.2):.1f}-{duration - min(8, duration * 0.2):.1f}ç§’",
            "estimated_outro": f"{duration - min(8, duration * 0.2):.1f}-{duration:.1f}ç§’",
            "intro_ratio": f"{intro_ratio:.1%}",
            "development_ratio": f"{development_ratio:.1%}",
            "outro_ratio": f"{outro_ratio:.1%}"
        }
    
    return analysis

def generate_visual_recommendations(result):
    """è¦–è¦šçš„è¦ç´ ã¸ã®å…·ä½“çš„ææ¡ˆ"""
    if "error" in result:
        return {"error": result["error"]}
    
    file_info = result["file_info"]
    audio_info = result["audio_analysis"]
    
    duration = file_info["duration_seconds"]
    estimated_bpm = audio_info["estimated_bpm"]
    dynamic_range = audio_info["dynamic_range_ratio"]
    
    recommendations = {
        "color_palette": [],
        "visual_rhythm": "",
        "camera_movement": "",
        "lighting_style": "",
        "composition_style": "",
        "timing_suggestions": {}
    }
    
    # BPMãƒ™ãƒ¼ã‚¹ã®è¦–è¦šãƒªã‚ºãƒ 
    if isinstance(estimated_bpm, (int, float)):
        beat_interval = 60 / estimated_bpm
        recommendations["timing_suggestions"]["beat_interval"] = f"{beat_interval:.2f}ç§’"
        
        if estimated_bpm < 80:
            recommendations["visual_rhythm"] = "ã‚†ã£ãã‚Šã¨ã—ãŸç‘æƒ³çš„ãªå‹•ãã€é•·ã„ãƒˆãƒ©ãƒ³ã‚¸ã‚·ãƒ§ãƒ³"
            recommendations["camera_movement"] = "éå¸¸ã«æ»‘ã‚‰ã‹ãªã‚¹ãƒ­ãƒ¼ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã€é™çš„ã‚«ãƒƒãƒˆãƒ¡ã‚¤ãƒ³"
        elif estimated_bpm <= 100:
            recommendations["visual_rhythm"] = "ç©ã‚„ã‹ã§æµã‚Œã‚‹ã‚ˆã†ãªå‹•ãã€å®‰å®šã—ãŸãƒšãƒ¼ã‚¹"
            recommendations["camera_movement"] = "æ»‘ã‚‰ã‹ãªãƒ‘ãƒ³ãƒ»ãƒ†ã‚£ãƒ«ãƒˆã€ç·©ã‚„ã‹ãªã‚ºãƒ¼ãƒ "
        else:
            recommendations["visual_rhythm"] = "ãƒªã‚ºãƒŸã‚«ãƒ«ã§æ´»ç™ºãªå‹•ãã€å®šæœŸçš„ãªå¤‰åŒ–"
            recommendations["camera_movement"] = "ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã€ãƒªã‚ºãƒ ã«åŒæœŸ"
    else:
        recommendations["visual_rhythm"] = "ä¸€å®šã§è½ã¡ç€ã„ãŸå‹•ãã€ãƒŸãƒ‹ãƒãƒ«ãªå¤‰åŒ–"
        recommendations["camera_movement"] = "é™çš„ã¾ãŸã¯éå¸¸ã«ã‚†ã£ãã‚Šã¨ã—ãŸå‹•ã"
    
    # ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãƒ¬ãƒ³ã‚¸ãƒ™ãƒ¼ã‚¹ã®ææ¡ˆ
    if dynamic_range > 3:
        recommendations["lighting_style"] = "ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã®å¼·ã„ç…§æ˜ã€ãƒ‰ãƒ©ãƒãƒãƒƒã‚¯ãªé™°å½±"
        recommendations["color_palette"] = ["æ·±ã„ãƒ–ãƒ«ãƒ¼", "é®®ã‚„ã‹ãªãƒ›ãƒ¯ã‚¤ãƒˆ", "ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã‚´ãƒ¼ãƒ«ãƒ‰"]
    elif dynamic_range > 2:
        recommendations["lighting_style"] = "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸç…§æ˜ã€é©åº¦ãªã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ"
        recommendations["color_palette"] = ["ã‚½ãƒ•ãƒˆã‚°ãƒ¬ãƒ¼", "æ¸©ã‹ã„ãƒ›ãƒ¯ã‚¤ãƒˆ", "æ·¡ã„ãƒ–ãƒ«ãƒ¼"]
    else:
        recommendations["lighting_style"] = "æŸ”ã‚‰ã‹ãå‡ä¸€ãªç…§æ˜ã€ãƒŸãƒ‹ãƒãƒ«ãªã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ"
        recommendations["color_palette"] = ["ã‚¯ãƒªãƒ¼ãƒ ãƒ›ãƒ¯ã‚¤ãƒˆ", "ãƒ©ã‚¤ãƒˆã‚°ãƒ¬ãƒ¼", "å¾®ç´°ãªã‚´ãƒ¼ãƒ«ãƒ‰"]
    
    # é•·ã•ãƒ™ãƒ¼ã‚¹ã®æ§‹æˆææ¡ˆ
    if duration < 30:
        recommendations["composition_style"] = "ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã§é›†ä¸­çš„ã€ã‚·ãƒ³ãƒ—ãƒ«ãª3æ®µæ§‹æˆ"
    elif duration <= 40:
        recommendations["composition_style"] = "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸ4æ®µæ§‹æˆã€ååˆ†ãªå±•é–‹æ™‚é–“"
    else:
        recommendations["composition_style"] = "ã‚†ã£ãŸã‚Šã¨ã—ãŸ5æ®µæ§‹æˆã€ååˆ†ãªä½™ç™½"
    
    return recommendations

def main():
    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    audio_file = "/home/runner/work/kamuicode-workflow/kamuicode-workflow/music-video-20250721-16406899626/music/generated-music.wav"
    
    print("ğŸµ éŸ³æ¥½åˆ†æå°‚é–€ãƒ¬ãƒãƒ¼ãƒˆå®Ÿè¡Œä¸­...")
    print(f"ğŸ“ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {audio_file}")
    print("=" * 80)
    
    # åˆ†æå®Ÿè¡Œ
    result = basic_wav_analysis(audio_file)
    
    # ç›®æ¨™ä»•æ§˜
    target_specs = {
        "duration": (30, 40),  # ç§’
        "bpm": (80, 100),      # BPMç¯„å›²
        "style": "ãƒŸãƒ‹ãƒãƒªã‚¹ãƒˆãƒ”ã‚¢ãƒã‚½ãƒ­",
        "structure": {
            "intro": 8,
            "development": (12, 16),
            "climax": (8, 10),
            "outro": (6, 8)
        }
    }
    
    if "error" in result:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
        return
    
    # è©³ç´°åˆ†æ
    plan_comparison = generate_plan_comparison(result, target_specs)
    structure_analysis = analyze_structure_sections(result, target_specs["structure"])
    visual_recommendations = generate_visual_recommendations(result)
    
    # 1. åŸºæœ¬æƒ…å ±ã®å ±å‘Š
    print("ğŸ“Š 1. åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±")
    print("-" * 40)
    file_info = result["file_info"]
    print(f"  ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_info['file_size_mb']} MB")
    print(f"  é•·ã•: {file_info['duration_seconds']} ç§’")
    print(f"  ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ: {file_info['sample_rate']} Hz")
    print(f"  ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {file_info['channels']}")
    print(f"  ãƒ“ãƒƒãƒˆæ·±åº¦: {file_info['sample_width_bytes'] * 8} bit")
    print()
    
    # 2. è´è¦šçš„åˆ†æï¼ˆæ¨å®šï¼‰
    print("ğŸ§ 2. è´è¦šçš„åˆ†æï¼ˆæ¨å®šãƒ™ãƒ¼ã‚¹ï¼‰")
    print("-" * 40)
    audio_info = result["audio_analysis"]
    print(f"  æ¨å®šBPM: {audio_info['estimated_bpm']}")
    print(f"  æœ€å¤§æŒ¯å¹…: {audio_info['max_amplitude']}")
    print(f"  RMSå¹³å‡: {audio_info['rms_average']}")
    print(f"  ãƒ€ã‚¤ãƒŠãƒŸã‚¯ã‚¹æ¯”: {audio_info['dynamic_range_ratio']}")
    print(f"  ã‚¨ãƒãƒ«ã‚®ãƒ¼ãƒ”ãƒ¼ã‚¯æ•°: {audio_info['energy_peaks_count']}")
    
    if audio_info['energy_peaks_count'] > 0:
        print(f"  ãƒ”ãƒ¼ã‚¯ä½ç½®: {audio_info['energy_peaks_times']}")
    print()
    
    # 3. æ§‹é€ åˆ†æ
    print("ğŸ—ï¸ 3. éŸ³æ¥½æ§‹é€ åˆ†æ")
    print("-" * 40)
    if "error" not in structure_analysis:
        actual = structure_analysis["actual_structure"]
        sections = structure_analysis["section_analysis"]
        print(f"  ç·é•·: {actual['total_duration']}ç§’")
        print(f"  æ¤œå‡ºãƒ”ãƒ¼ã‚¯æ•°: {actual['peak_count']}")
        print(f"  æ¨å®šã‚¤ãƒ³ãƒˆãƒ­: {sections['estimated_intro']}")
        print(f"  æ¨å®šå±•é–‹éƒ¨: {sections['estimated_development']}")
        print(f"  æ¨å®šã‚¢ã‚¦ãƒˆãƒ­: {sections['estimated_outro']}")
    print()
    
    # 4. è¨ˆç”»ã¨ã®æ¯”è¼ƒ
    print("ğŸ“‹ 4. è¨ˆç”»ç›®æ¨™ã¨ã®æ¯”è¼ƒ")
    print("-" * 40)
    if "error" not in plan_comparison:
        duration_comp = plan_comparison["duration"]
        bpm_comp = plan_comparison["bpm"]
        
        print(f"  é•·ã•: {duration_comp['status']}")
        print(f"    å®Ÿéš›: {duration_comp['actual']}")
        print(f"    ç›®æ¨™: {duration_comp['target']}")
        print(f"    å·®åˆ†: {duration_comp['deviation']}")
        print()
        print(f"  BPM: {bpm_comp['status']}")
        print(f"    å®Ÿéš›: {bpm_comp['actual']}")
        print(f"    ç›®æ¨™: {bpm_comp['target']}")
        print(f"    å·®åˆ†: {bpm_comp['deviation']}")
    print()
    
    # 5. è¦–è¦šçš„è¦ç´ ã¸ã®ç¤ºå”†
    print("ğŸ¨ 5. ç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¾®èª¿æ•´ã¸ã®ç¤ºå”†")
    print("-" * 40)
    if "error" not in visual_recommendations:
        vis_rec = visual_recommendations
        print(f"  æ¨å¥¨è‰²å½©: {', '.join(vis_rec['color_palette'])}")
        print(f"  è¦–è¦šãƒªã‚ºãƒ : {vis_rec['visual_rhythm']}")
        print(f"  ã‚«ãƒ¡ãƒ©å‹•ä½œ: {vis_rec['camera_movement']}")
        print(f"  ç…§æ˜ã‚¹ã‚¿ã‚¤ãƒ«: {vis_rec['lighting_style']}")
        print(f"  æ§‹æˆã‚¹ã‚¿ã‚¤ãƒ«: {vis_rec['composition_style']}")
        
        if "beat_interval" in vis_rec["timing_suggestions"]:
            print(f"  ãƒ“ãƒ¼ãƒˆé–“éš”: {vis_rec['timing_suggestions']['beat_interval']}")
    print()
    
    # 6. ç·åˆè©•ä¾¡
    print("ğŸ“ˆ 6. ç·åˆè©•ä¾¡ãƒ»æ¨å¥¨äº‹é …")
    print("-" * 40)
    
    # é©åˆæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
    score = 0
    max_score = 2
    
    if "error" not in plan_comparison:
        if "âœ…" in plan_comparison["duration"]["status"]:
            score += 1
        if "âœ…" in plan_comparison["bpm"]["status"]:
            score += 1
    
    compatibility_percentage = (score / max_score) * 100
    print(f"  è¨ˆç”»é©åˆæ€§: {compatibility_percentage:.0f}% ({score}/{max_score}é …ç›®é©åˆ)")
    
    if compatibility_percentage >= 80:
        print("  ğŸŸ¢ ç·åˆè©•ä¾¡: å„ªç§€ - ãã®ã¾ã¾å‹•ç”»åˆ¶ä½œã«é€²è¡Œå¯èƒ½")
    elif compatibility_percentage >= 60:
        print("  ğŸŸ¡ ç·åˆè©•ä¾¡: è‰¯å¥½ - è»½å¾®ãªèª¿æ•´ã§å‹•ç”»åˆ¶ä½œå¯èƒ½")
    else:
        print("  ğŸ”´ ç·åˆè©•ä¾¡: è¦æ”¹å–„ - å¤§å¹…ãªèª¿æ•´ã¾ãŸã¯å†ç”Ÿæˆæ¨å¥¨")
    
    print()
    print("ğŸ“ æ¨å¥¨æ¬¡ã‚¹ãƒ†ãƒƒãƒ—:")
    if compatibility_percentage >= 80:
        print("  1. ç”»åƒç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«éŸ³æ¥½ç‰¹å¾´ã‚’åæ˜ ")
        print("  2. å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ¨å¥¨ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã‚’çµ„ã¿è¾¼ã¿")
        print("  3. è‰²å½©ãƒ‘ãƒ¬ãƒƒãƒˆã‚’è¦–è¦šã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«é©ç”¨")
    else:
        print("  1. éŸ³æ¥½ã®å†ç”Ÿæˆã¾ãŸã¯èª¿æ•´ã‚’æ¤œè¨")
        print("  2. ã‚ˆã‚ŠæŸ”è»Ÿãªç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ")
        print("  3. éŸ³æ¥½ç‰¹å¾´ã«åˆã‚ã›ãŸæ–°è¦æˆ¦ç•¥ç«‹æ¡ˆ")
    
    # çµæœã‚’JSONã§ä¿å­˜
    analysis_summary = {
        "timestamp": datetime.now().isoformat(),
        "file_analysis": result,
        "plan_comparison": plan_comparison,
        "structure_analysis": structure_analysis,
        "visual_recommendations": visual_recommendations,
        "compatibility_score": compatibility_percentage,
        "next_steps": "ç”»åƒãƒ»å‹•ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¾®èª¿æ•´" if compatibility_percentage >= 80 else "éŸ³æ¥½èª¿æ•´æ¤œè¨"
    }
    
    output_file = "/home/runner/work/kamuicode-workflow/kamuicode-workflow/music-video-20250721-16406899626/analysis/music_analysis_report.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_summary, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ä¿å­˜: {output_file}")
    except Exception as e:
        print(f"\nâš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n" + "=" * 80)
    print("âœ… éŸ³æ¥½åˆ†æå°‚é–€ãƒ¬ãƒãƒ¼ãƒˆå®Œäº†ï¼")
    
    return analysis_summary

if __name__ == "__main__":
    main()